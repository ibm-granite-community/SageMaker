{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559e8037-005b-4130-916c-ae7b5dd12120",
   "metadata": {},
   "source": [
    "# Deploying Granite 3.3 instruct models in Amazon SageMaker\n",
    "\n",
    "## Introduction to Granite 3.3 instruct Models\n",
    "\n",
    "IBM Granite 3.3, the third generation of the Granite series of large language models (LLMs) and complementary tools. Reflecting our focus on the balance between powerful and practical, the new IBM Granite 3.3 models deliver state-of-the-art performance relative to model size while maximizing safety, speed and cost-efficiency for enterprise use cases.\n",
    "\n",
    "**IBM Granite 3.3 family include**: \n",
    "- Granite 3.3. Langauge, Granite 3.2 Language, Granite 3.1 Language and Granite 3.0 Language Models\n",
    "- Granite Vision Models\n",
    "- Granite Speech\n",
    "- Granite Embedding Models\n",
    "- Granite Code Models\n",
    "- Granite Guardian Models\n",
    "- Granite Time Series Models\n",
    "- Granite Experiments, Geospatial Models\n",
    "\n",
    "The new Granite 3.3 8B and 2B language models are designed as 'workhorse' models for enterprise AI, delivering strong performance for tasks such as Retrieval Augmented Geneneration (RAG), classification, summarization, entity extraction, and tool use. These compact, versatile models are designed to be fine-tuned with enterprise data and seamlessly integrated across diverse business environments or workflows.\n",
    "\n",
    "The Granite 3.3 models were trained on over 12 trillion tokens on data taken from 12 different natural languages and 116 different programming languages, using a novel two-stage training method, leveraging results from several thousand experiments designed to optimize data quality, data selection, and training parameters.\n",
    "\n",
    "IBM has released the Granite 3.3 models to open source under the permissive Apache 2.0 license, enabling their use for both research and commercial purposes with no restrictions. The models are available on Amazon SageMaker JumpStart, the AWS Marketplace, and on [Hugging Face](https://huggingface.co/ibm-granite).\n",
    "\n",
    "In this notebook, we will deploy the Granite 3.3 models on Amazon SageMaker.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "- Before running this notebook, please make sure you got this notebook from the model catalog on SageMaker AWS Management Console.\n",
    "- *Note*: Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "- Ensure that the IAM role used has **AmazonSageMakerFullAccess**.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. **Deploying Granite 3.3 models in Amazon SageMaker**\n",
    "    - To subscribe to the model package\n",
    "    - Select the model package\n",
    "2. **Create an endpoint and perform real-time inference**\n",
    "    - Define the endpoint configuration\n",
    "    - Create the endpoint\n",
    "3. **Run inference with the model**\n",
    "    - Example : This is an example model request! I think LLMs are cool.\n",
    "4. **Clean-up**\n",
    "    - Delete the endpoint\n",
    "    - Delete the model    \n",
    "\n",
    "## Usage Instructions\n",
    "\n",
    "You can run this notebook one cell at a time by using **Shift+Enter** to run a cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e559f9-e514-4aae-9b15-d4b626f9a94c",
   "metadata": {},
   "source": [
    "## Deploying Granite 3.3 models in Amazon SageMaker\n",
    "\n",
    "### To subscribe to the model package:\n",
    "\n",
    "1. Open the model package listing page [IBM Granite 3.3 2b instruct ]()\n",
    "2. On the AWS Marketplace listing, click on the Continue to subscribe button.\n",
    "3. On the Subscribe to this software page, review and click on \"Accept Offer\" if you and your organization agrees with EULA, pricing, and support terms.\n",
    "4. Once you click on Continue to configuration button and then choose a region, you will see a Product Arn displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5942175-4354-4bec-8e27-6ab4f2c0d541",
   "metadata": {},
   "source": [
    "### 1. Select the model package\n",
    "\n",
    "Confirm that you received this notebook from model catalog on SageMaker AWS Management Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca3851-308a-4144-a762-ea9f024796f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_map = {\n",
    "    \"us-east-1\": \"\",\n",
    "    \"us-east-2\": \"\",\n",
    "    \"us-west-1\": \"\",\n",
    "    \"us-west-2\": \"\",\n",
    "    \"ca-central-1\": \"\",\n",
    "    \"eu-central-1\": \"\",\n",
    "    \"eu-west-1\": \"\",\n",
    "    \"eu-west-2\": \"\",\n",
    "    \"eu-west-3\": \"\",\n",
    "    \"eu-north-1\": \"\",\n",
    "    \"ap-southeast-1\": \"\",\n",
    "    \"ap-southeast-2\": \"\",\n",
    "    \"ap-northeast-2\": \"\",\n",
    "    \"ap-northeast-1\": \"\",\n",
    "    \"ap-south-1\": \"\",\n",
    "    \"sa-east-1\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10574fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -U sagemaker -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae3d8a-f29f-4c98-a6bf-b8c386f11ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import ModelPackage, get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66604be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "try:\n",
    "    execution_role_arn = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    execution_role_arn = None\n",
    "\n",
    "if execution_role_arn == None:\n",
    "    execution_role_arn = input(\"Enter your execution role ARN: \")\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "runtime_sm_client = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "print (\"execution_role_arn: \", execution_role_arn)\n",
    "print (\"region: \", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if region not in model_package_map.keys():\n",
    "    raise \"UNSUPPORTED REGION\"\n",
    "\n",
    "model_package_arn = model_package_map[region]\n",
    "\n",
    "print (\"model_package_arn: \", model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd157bea",
   "metadata": {},
   "source": [
    "## Create an endpoint and perform real-time inference\n",
    "\n",
    "In this example, we're deploying IBM  Granite-3.3-2b-instruct on an Amazon SageMaker real-time endpoint hosted on a GPU instance. If you need general information on real-time inference with Amazon SageMaker, please refer to the SageMaker documentation.\n",
    "\n",
    "For flexibility, you can pick from two sample configurations, depending your use case and the instances types available to you. Please make sure to run just one of the configuration cells below.\n",
    "\n",
    "The endpoint configuration focuses on cost efficiency. It uses a ml.g6e.2xlarge instance. This instance has a LS40 GPU. The IBM Granite-3.3-2b-Instruct model is a fine-tuned, instruction-following language model that supports long-context inputs and is optimized for scenarios requiring cost-efficient and high-performance inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7e59f",
   "metadata": {},
   "source": [
    "### 2. Define the endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"granite-3-3-2b-instruct\"\n",
    "inference_instance_type = \"ml.g6e.2xlarge\"\n",
    "model_download_timeout = 3600\n",
    "health_check_timeout = 900\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e1911",
   "metadata": {},
   "source": [
    "### 3. Create the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81557d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=execution_role_arn, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# create a unique endpoint name\n",
    "timestamp = \"{:%Y-%m-%d-%H-%M-%S}\".format(datetime.now())\n",
    "endpoint_name = f\"{model_name}-{timestamp}\"\n",
    "print(f\"Deploying endpoint {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328703cb-8b3f-4c18-b2e7-87092dabeadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the model\n",
    "deployed_model = model.deploy(\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=inference_instance_type,\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd90e3",
   "metadata": {},
   "source": [
    "\n",
    "If you have already deployed your model, you can also access it via your chosen endpoint_name and sagemaker_session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec2c1a",
   "metadata": {},
   "source": [
    "SageMaker will now create our endpoint and deploy the model to it. This can takes a 10-15 minutes. Once the endpoint is in service, you will be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25f153",
   "metadata": {},
   "source": [
    "## Run inference with the model\n",
    "\n",
    "Now that we have the Granite 3.3 2b instruct model loaded and deployed to a SageMaker endpoint, we can start testing. We use the predict method from the predictor to run inference on our endpoint. We can inference with different parameters to impact the generation. Parameters can be defined as in the parameters attribute of the payload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1060f40",
   "metadata": {},
   "source": [
    "### 4. This is an example model request! I think LLMs are cool. \n",
    "\n",
    "In this example, we want to test sample prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"This is an example model request! I think LLMs are cool.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fba4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for llm\n",
    "payload_1 = {\n",
    "    \"inputs\": prompt_1,\n",
    "    \"parameters\": {\n",
    "        \"details\": True,\n",
    "        \"max_tokens\": 512\n",
    "    }\n",
    "}\n",
    "\n",
    "# send request to endpoint\n",
    "response_1 = deployed_model.predict(\n",
    "    data=json.dumps(payload_1),\n",
    "    initial_args={\"Accept\": \"application/json\", \"ContentType\": \"application/json\"},\n",
    ").decode(\"utf-8\")\n",
    "\n",
    "response_list = json.loads(response_1)[0]\n",
    "print(response_list[\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943e029-2633-4f74-8440-fe48d1348bb7",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "\n",
    "Please don't forget to run the cells below to delete all resources and avoid unecessary charges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0221806",
   "metadata": {},
   "source": [
    "### 7. Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7ddde-e511-40e2-8313-55c3aa6c85e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(endpoint_name)\n",
    "model.sagemaker_session.delete_endpoint_config(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62a004",
   "metadata": {},
   "source": [
    "### 8. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89492dab",
   "metadata": {},
   "source": [
    "Thank you for trying out IBM Granite 3.3 Model on SageMaker. We have only scratched the surface of what you can do with this model.\n",
    "\n",
    "Welcome to your IBM Granite Model support experience! You can view, start, or contribute to community discussions (sign in to contribute). View supplemental resources and  [sign](https://www.ibm.com/mysupport/s/?language=en_US) in to open a new case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa81e67",
   "metadata": {},
   "source": [
    "## Would you like to provide feedback?\n",
    "\n",
    "Please let us know your comments about our family of Granite 3.3 instruct models by visiting our collection. Select the repository of the model you would like to provide feedback about. Then, go to Community tab, and click on New discussion. Alternatively, you can also post any questions/comments on our github discussions page."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
